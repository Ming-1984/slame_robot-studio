#!/usr/bin/env python3
"""
ğŸ§ª å¹¶è¡Œè®¡ç®—åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•é¢„æµ‹æ€§ç›®æ ‡è®¡ç®—å’Œå¹¶è¡Œå‰æ²¿ç‚¹å¤„ç†åŠŸèƒ½

åŠŸèƒ½ï¼š
1. æµ‹è¯•å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨çš„åŸºæœ¬åŠŸèƒ½
2. éªŒè¯é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹çš„å‡†ç¡®æ€§
3. æµ‹è¯•çŠ¶æ€åŒæ­¥å’Œä¸€è‡´æ€§ä¿è¯
4. æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–å»ºè®®

ä½œè€…: Auroraæ¢ç´¢ç³»ç»Ÿ
æ—¥æœŸ: 2025-07-21
"""

import rclpy
from rclpy.node import Node
import time
import threading
import numpy as np
from typing import List, Dict, Tuple
from nav_msgs.msg import OccupancyGrid
from geometry_msgs.msg import Point, Twist
from parallel_computation_manager import ParallelComputationManager
from predictive_frontier_detector import PredictiveFrontierDetector

# å¯¼å…¥å‰æ²¿ç‚¹æ£€æµ‹å™¨
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from aurora_explorer.optimized_frontier_detector import OptimizedFrontierDetector, OptimizedFrontierPoint

class ParallelComputationTester(Node):
    """å¹¶è¡Œè®¡ç®—åŠŸèƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        super().__init__('parallel_computation_tester')
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.parallel_manager = ParallelComputationManager(self, max_workers=4)
        self.predictive_detector = PredictiveFrontierDetector(self, self.parallel_manager)
        self.base_detector = OptimizedFrontierDetector()
        
        # æµ‹è¯•æ•°æ®
        self.test_maps = self._generate_test_maps()
        self.test_scenarios = self._generate_test_scenarios()
        
        # æµ‹è¯•ç»“æœ
        self.test_results = {}
        
        self.get_logger().info('ğŸ§ª å¹¶è¡Œè®¡ç®—åŠŸèƒ½æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ')
        
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.get_logger().info('ğŸš€ å¼€å§‹å¹¶è¡Œè®¡ç®—åŠŸèƒ½æµ‹è¯•')
        
        try:
            # æµ‹è¯•1ï¼šåŸºç¡€å¹¶è¡Œè®¡ç®—åŠŸèƒ½
            self.test_basic_parallel_computation()
            
            # æµ‹è¯•2ï¼šé¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹
            self.test_predictive_frontier_detection()
            
            # æµ‹è¯•3ï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•
            self.test_performance_benchmark()
            
            # æµ‹è¯•4ï¼šçŠ¶æ€åŒæ­¥æµ‹è¯•
            self.test_state_synchronization()
            
            # æµ‹è¯•5ï¼šç¼“å­˜ç®¡ç†æµ‹è¯•
            self.test_cache_management()
            
            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            self._generate_test_report()
            
        except Exception as e:
            self.get_logger().error(f'âŒ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}')
            
    def test_basic_parallel_computation(self):
        """æµ‹è¯•åŸºç¡€å¹¶è¡Œè®¡ç®—åŠŸèƒ½"""
        self.get_logger().info('ğŸ“‹ æµ‹è¯•1: åŸºç¡€å¹¶è¡Œè®¡ç®—åŠŸèƒ½')
        
        start_time = time.time()
        task_ids = []
        
        # æäº¤å¤šä¸ªè®¡ç®—ä»»åŠ¡
        for i, test_map in enumerate(self.test_maps[:3]):
            task_id = self.parallel_manager.submit_predictive_computation(
                task_type=f"test_frontier_detection_{i}",
                robot_position=(0.0, 0.0),
                map_data=test_map,
                computation_func=self._mock_frontier_detection,
                priority=i
            )
            task_ids.append(task_id)
            
        # ç­‰å¾…ç»“æœ
        results = []
        for task_id in task_ids:
            result = self.parallel_manager.get_computation_result(task_id, timeout=5.0)
            if result:
                results.append(result)
                
        test_time = time.time() - start_time
        
        # è®°å½•ç»“æœ
        self.test_results['basic_parallel'] = {
            'submitted_tasks': len(task_ids),
            'completed_tasks': len(results),
            'total_time': test_time,
            'success_rate': len(results) / len(task_ids) if task_ids else 0.0
        }
        
        self.get_logger().info(
            f'âœ… åŸºç¡€å¹¶è¡Œè®¡ç®—æµ‹è¯•å®Œæˆ: {len(results)}/{len(task_ids)}ä»»åŠ¡æˆåŠŸ, '
            f'è€—æ—¶: {test_time:.2f}s'
        )
        
    def test_predictive_frontier_detection(self):
        """æµ‹è¯•é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹"""
        self.get_logger().info('ğŸ“‹ æµ‹è¯•2: é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹')
        
        start_time = time.time()
        
        # æ¨¡æ‹Ÿæœºå™¨äººè¿åŠ¨
        robot_positions = [(i * 0.5, 0.0) for i in range(10)]
        robot_velocities = [Twist() for _ in range(10)]
        for vel in robot_velocities:
            vel.linear.x = 0.5
            
        prediction_results = []
        
        for i, (pos, vel) in enumerate(zip(robot_positions, robot_velocities)):
            # æ›´æ–°æœºå™¨äººçŠ¶æ€
            self.predictive_detector.update_robot_state(pos, 0.0, vel)
            
            # è§¦å‘é¢„æµ‹æ£€æµ‹
            task_id = self.predictive_detector.trigger_predictive_detection(
                self.test_maps[0], Point(x=5.0, y=0.0, z=0.0)
            )
            
            if task_id:
                time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
                
                # è·å–é¢„æµ‹ç»“æœ
                predicted_frontiers = self.predictive_detector.get_predicted_frontiers(pos)
                if predicted_frontiers:
                    prediction_results.append(len(predicted_frontiers))
                    
        test_time = time.time() - start_time
        
        # è®°å½•ç»“æœ
        self.test_results['predictive_detection'] = {
            'prediction_attempts': len(robot_positions),
            'successful_predictions': len(prediction_results),
            'average_frontiers': np.mean(prediction_results) if prediction_results else 0.0,
            'total_time': test_time,
            'success_rate': len(prediction_results) / len(robot_positions)
        }
        
        self.get_logger().info(
            f'âœ… é¢„æµ‹æ€§æ£€æµ‹æµ‹è¯•å®Œæˆ: {len(prediction_results)}/{len(robot_positions)}æ¬¡æˆåŠŸ, '
            f'å¹³å‡å‰æ²¿ç‚¹æ•°: {np.mean(prediction_results) if prediction_results else 0:.1f}, '
            f'è€—æ—¶: {test_time:.2f}s'
        )
        
    def test_performance_benchmark(self):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        self.get_logger().info('ğŸ“‹ æµ‹è¯•3: æ€§èƒ½åŸºå‡†æµ‹è¯•')
        
        # ä¸²è¡Œè®¡ç®—åŸºå‡†
        serial_start = time.time()
        serial_results = []
        for test_map in self.test_maps:
            result = self._mock_frontier_detection(map_data=test_map)
            serial_results.append(result)
        serial_time = time.time() - serial_start
        
        # å¹¶è¡Œè®¡ç®—åŸºå‡†
        parallel_start = time.time()
        task_ids = []
        for i, test_map in enumerate(self.test_maps):
            task_id = self.parallel_manager.submit_predictive_computation(
                task_type=f"benchmark_test_{i}",
                robot_position=(0.0, 0.0),
                map_data=test_map,
                computation_func=self._mock_frontier_detection,
                priority=0
            )
            task_ids.append(task_id)
            
        parallel_results = []
        for task_id in task_ids:
            result = self.parallel_manager.get_computation_result(task_id, timeout=10.0)
            if result:
                parallel_results.append(result)
        parallel_time = time.time() - parallel_start
        
        # è®¡ç®—æ€§èƒ½æå‡
        speedup = serial_time / parallel_time if parallel_time > 0 else 0.0
        
        # è®°å½•ç»“æœ
        self.test_results['performance_benchmark'] = {
            'serial_time': serial_time,
            'parallel_time': parallel_time,
            'speedup': speedup,
            'serial_tasks': len(serial_results),
            'parallel_tasks': len(parallel_results),
            'efficiency': speedup / 4.0  # 4ä¸ªå·¥ä½œçº¿ç¨‹
        }
        
        self.get_logger().info(
            f'âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ: ä¸²è¡Œ{serial_time:.2f}s vs å¹¶è¡Œ{parallel_time:.2f}s, '
            f'åŠ é€Ÿæ¯”: {speedup:.2f}x, æ•ˆç‡: {speedup/4.0:.1%}'
        )
        
    def test_state_synchronization(self):
        """æµ‹è¯•çŠ¶æ€åŒæ­¥"""
        self.get_logger().info('ğŸ“‹ æµ‹è¯•4: çŠ¶æ€åŒæ­¥æµ‹è¯•')
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹åŒæ—¶æ›´æ–°çŠ¶æ€
        def update_robot_state(thread_id):
            for i in range(10):
                pos = (thread_id * 10 + i, 0.0)
                self.predictive_detector.update_robot_state(pos, 0.0)
                time.sleep(0.01)
                
        threads = []
        for i in range(4):
            thread = threading.Thread(target=update_robot_state, args=(i,))
            threads.append(thread)
            thread.start()
            
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
            
        # æ£€æŸ¥çŠ¶æ€ä¸€è‡´æ€§
        final_state = self.predictive_detector.current_robot_state
        
        self.test_results['state_synchronization'] = {
            'threads_count': len(threads),
            'final_state_valid': final_state is not None,
            'state_timestamp': final_state.timestamp if final_state else 0.0
        }
        
        self.get_logger().info('âœ… çŠ¶æ€åŒæ­¥æµ‹è¯•å®Œæˆ: çŠ¶æ€ä¸€è‡´æ€§æ­£å¸¸')
        
    def test_cache_management(self):
        """æµ‹è¯•ç¼“å­˜ç®¡ç†"""
        self.get_logger().info('ğŸ“‹ æµ‹è¯•5: ç¼“å­˜ç®¡ç†æµ‹è¯•')
        
        # æäº¤ç›¸åŒçš„è®¡ç®—ä»»åŠ¡å¤šæ¬¡
        task_ids = []
        for i in range(5):
            task_id = self.parallel_manager.submit_predictive_computation(
                task_type="cache_test",
                robot_position=(0.0, 0.0),
                map_data=self.test_maps[0],
                computation_func=self._mock_frontier_detection,
                priority=0
            )
            task_ids.append(task_id)
            time.sleep(0.1)
            
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.parallel_manager.get_statistics()
        
        self.test_results['cache_management'] = {
            'cache_hit_rate': stats.get('cache_hit_rate', 0.0),
            'cache_size': stats.get('cache_size', 0),
            'total_tasks': stats.get('total_tasks', 0)
        }
        
        self.get_logger().info(
            f'âœ… ç¼“å­˜ç®¡ç†æµ‹è¯•å®Œæˆ: å‘½ä¸­ç‡{stats.get("cache_hit_rate", 0.0):.1%}, '
            f'ç¼“å­˜å¤§å°: {stats.get("cache_size", 0)}'
        )
        
    def _generate_test_maps(self) -> List[OccupancyGrid]:
        """ç”Ÿæˆæµ‹è¯•åœ°å›¾"""
        maps = []
        
        for i in range(5):
            map_data = OccupancyGrid()
            map_data.info.resolution = 0.1
            map_data.info.width = 100
            map_data.info.height = 100
            map_data.info.origin.position.x = -5.0
            map_data.info.origin.position.y = -5.0
            
            # ç”Ÿæˆéšæœºåœ°å›¾æ•°æ®
            data = np.random.choice([0, 100, -1], size=10000, p=[0.7, 0.2, 0.1])
            map_data.data = data.tolist()
            
            maps.append(map_data)
            
        return maps
        
    def _generate_test_scenarios(self) -> List[Dict]:
        """ç”Ÿæˆæµ‹è¯•åœºæ™¯"""
        return [
            {
                'name': 'simple_exploration',
                'robot_start': (0.0, 0.0),
                'target_area': (5.0, 5.0),
                'expected_frontiers': 10
            },
            {
                'name': 'complex_environment',
                'robot_start': (2.0, 2.0),
                'target_area': (8.0, 8.0),
                'expected_frontiers': 15
            }
        ]
        
    def _mock_frontier_detection(self, map_data: OccupancyGrid, **kwargs) -> List[OptimizedFrontierPoint]:
        """æ¨¡æ‹Ÿå‰æ²¿ç‚¹æ£€æµ‹"""
        # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
        time.sleep(0.1)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿå‰æ²¿ç‚¹
        frontiers = []
        for i in range(np.random.randint(5, 15)):
            frontier = OptimizedFrontierPoint(
                x=np.random.uniform(-5.0, 5.0),
                y=np.random.uniform(-5.0, 5.0),
                size=np.random.randint(10, 50),
                information_gain=np.random.uniform(0.1, 1.0)
            )
            frontiers.append(frontier)
            
        return frontiers
        
    def _generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        self.get_logger().info('ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š')
        self.get_logger().info('=' * 60)
        
        for test_name, results in self.test_results.items():
            self.get_logger().info(f'ğŸ“‹ {test_name}:')
            for key, value in results.items():
                if isinstance(value, float):
                    self.get_logger().info(f'  {key}: {value:.3f}')
                else:
                    self.get_logger().info(f'  {key}: {value}')
            self.get_logger().info('-' * 40)
            
        # è®¡ç®—æ€»ä½“è¯„åˆ†
        overall_score = self._calculate_overall_score()
        self.get_logger().info(f'ğŸ† æ€»ä½“è¯„åˆ†: {overall_score:.1f}/100')
        
    def _calculate_overall_score(self) -> float:
        """è®¡ç®—æ€»ä½“è¯„åˆ†"""
        score = 0.0
        
        # åŸºç¡€åŠŸèƒ½è¯„åˆ† (25åˆ†)
        if 'basic_parallel' in self.test_results:
            basic_score = self.test_results['basic_parallel']['success_rate'] * 25
            score += basic_score
            
        # é¢„æµ‹åŠŸèƒ½è¯„åˆ† (25åˆ†)
        if 'predictive_detection' in self.test_results:
            pred_score = self.test_results['predictive_detection']['success_rate'] * 25
            score += pred_score
            
        # æ€§èƒ½è¯„åˆ† (25åˆ†)
        if 'performance_benchmark' in self.test_results:
            perf_score = min(25, self.test_results['performance_benchmark']['speedup'] * 6.25)
            score += perf_score
            
        # ç¼“å­˜è¯„åˆ† (25åˆ†)
        if 'cache_management' in self.test_results:
            cache_score = self.test_results['cache_management']['cache_hit_rate'] * 25
            score += cache_score
            
        return score

def main():
    """ä¸»å‡½æ•°"""
    rclpy.init()
    
    tester = ParallelComputationTester()
    
    try:
        tester.run_all_tests()
    except KeyboardInterrupt:
        tester.get_logger().info('ğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­')
    except Exception as e:
        tester.get_logger().error(f'âŒ æµ‹è¯•å¼‚å¸¸: {e}')
    finally:
        tester.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
