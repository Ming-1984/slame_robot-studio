#!/usr/bin/env python3
"""
ğŸ”® é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹å™¨
åœ¨å½“å‰ç›®æ ‡æ‰§è¡Œè¿‡ç¨‹ä¸­å¹¶è¡Œæ£€æµ‹å’Œè¯„ä¼°ä¸‹ä¸€æ‰¹å‰æ²¿ç‚¹

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹ï¼šåŸºäºæœºå™¨äººè¿åŠ¨è½¨è¿¹é¢„æµ‹æœªæ¥ä½ç½®
2. å¹¶è¡Œè®¡ç®—ï¼šåœ¨åå°æŒç»­æ›´æ–°å‰æ²¿ç‚¹ä¿¡æ¯
3. æ™ºèƒ½è§¦å‘ï¼šæ ¹æ®å¯¼èˆªè¿›åº¦å’Œåœ°å›¾å˜åŒ–æ™ºèƒ½è§¦å‘é‡æ–°è®¡ç®—
4. ç»“æœé¢„ç¼“å­˜ï¼šæå‰å‡†å¤‡å¤šä¸ªå€™é€‰ç›®æ ‡ç‚¹

ç®—æ³•ç‰¹ç‚¹ï¼š
- è¿åŠ¨é¢„æµ‹ï¼šåŸºäºå½“å‰é€Ÿåº¦å’Œç›®æ ‡é¢„æµ‹æœºå™¨äººæœªæ¥ä½ç½®
- å¢é‡æ›´æ–°ï¼šåªæ›´æ–°åœ°å›¾å˜åŒ–åŒºåŸŸçš„å‰æ²¿ç‚¹
- ä¼˜å…ˆçº§æ’åºï¼šæ ¹æ®æ¢ç´¢ä»·å€¼é¢„æ’åºå€™é€‰ç›®æ ‡
- è‡ªé€‚åº”è§¦å‘ï¼šæ ¹æ®ç³»ç»Ÿè´Ÿè½½å’Œæ¢ç´¢è¿›åº¦è°ƒæ•´è®¡ç®—é¢‘ç‡

ä½œè€…: Auroraæ¢ç´¢ç³»ç»Ÿ
æ—¥æœŸ: 2025-07-21
"""

import time
import math
import threading
from typing import List, Optional, Tuple, Dict, Set
from dataclasses import dataclass, field
import numpy as np
from nav_msgs.msg import OccupancyGrid
from geometry_msgs.msg import Point, Twist
import rclpy
from rclpy.node import Node

# å¯¼å…¥ç°æœ‰æ¨¡å—
from parallel_computation_manager import ParallelComputationManager, ComputationResult

# å¯¼å…¥å‰æ²¿ç‚¹æ£€æµ‹å™¨
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from aurora_explorer.optimized_frontier_detector import OptimizedFrontierDetector, OptimizedFrontierPoint

@dataclass
class PredictedRobotState:
    """é¢„æµ‹çš„æœºå™¨äººçŠ¶æ€"""
    position: Tuple[float, float]
    yaw: float
    timestamp: float
    confidence: float = 1.0

@dataclass
class FrontierPrediction:
    """å‰æ²¿ç‚¹é¢„æµ‹ç»“æœ"""
    frontiers: List[OptimizedFrontierPoint]
    predicted_robot_state: PredictedRobotState
    computation_time: float
    map_hash: str
    validity_score: float = 1.0

class PredictiveFrontierDetector:
    """é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹å™¨"""
    
    def __init__(self, node: Node, computation_manager: ParallelComputationManager):
        """
        åˆå§‹åŒ–é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹å™¨
        
        Args:
            node: ROS2èŠ‚ç‚¹
            computation_manager: å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨
        """
        self.node = node
        self.computation_manager = computation_manager
        
        # åŸºç¡€å‰æ²¿ç‚¹æ£€æµ‹å™¨
        self.base_detector = OptimizedFrontierDetector(
            map_resolution=0.05,
            robot_radius=0.3
        )
        
        # é¢„æµ‹å‚æ•°
        self.prediction_horizon = 10.0  # é¢„æµ‹æ—¶é—´èŒƒå›´(ç§’)
        self.prediction_interval = 2.0  # é¢„æµ‹é—´éš”(ç§’)
        self.motion_prediction_samples = 5  # è¿åŠ¨é¢„æµ‹é‡‡æ ·ç‚¹æ•°
        
        # çŠ¶æ€è·Ÿè¸ª
        self.current_robot_state = None
        self.robot_velocity = None
        self.last_prediction_time = 0.0
        self.active_predictions: Dict[str, FrontierPrediction] = {}
        
        # åœ°å›¾å˜åŒ–æ£€æµ‹
        self.last_map_hash = ""
        self.map_change_threshold = 0.1  # åœ°å›¾å˜åŒ–é˜ˆå€¼
        self.significant_map_regions: Set[Tuple[int, int]] = set()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.prediction_stats = {
            'total_predictions': 0,
            'successful_predictions': 0,
            'cache_hits': 0,
            'average_prediction_time': 0.0,
            'prediction_accuracy': 0.0
        }
        
        # çº¿ç¨‹å®‰å…¨
        self.state_lock = threading.RLock()
        
        self.node.get_logger().info('ğŸ”® é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ')
        
    def update_robot_state(self, position: Tuple[float, float], yaw: float, velocity: Twist = None):
        """
        æ›´æ–°æœºå™¨äººçŠ¶æ€
        
        Args:
            position: æœºå™¨äººä½ç½®
            yaw: æœºå™¨äººæœå‘
            velocity: æœºå™¨äººé€Ÿåº¦
        """
        with self.state_lock:
            self.current_robot_state = PredictedRobotState(
                position=position,
                yaw=yaw,
                timestamp=time.time()
            )
            
            if velocity:
                self.robot_velocity = velocity
                
    def trigger_predictive_detection(self, 
                                   current_map: OccupancyGrid,
                                   current_goal: Optional[Point] = None,
                                   force_update: bool = False) -> str:
        """
        è§¦å‘é¢„æµ‹æ€§å‰æ²¿ç‚¹æ£€æµ‹
        
        Args:
            current_map: å½“å‰åœ°å›¾
            current_goal: å½“å‰ç›®æ ‡ç‚¹
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
            
        Returns:
            str: ä»»åŠ¡ID
        """
        current_time = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘é¢„æµ‹
        if not force_update and not self._should_trigger_prediction(current_map, current_time):
            return ""
            
        # ç”Ÿæˆé¢„æµ‹çš„æœºå™¨äººçŠ¶æ€
        predicted_states = self._generate_predicted_robot_states(current_goal)
        
        if not predicted_states:
            return ""
            
        # ä¸ºæ¯ä¸ªé¢„æµ‹çŠ¶æ€æäº¤è®¡ç®—ä»»åŠ¡
        task_ids = []
        for i, predicted_state in enumerate(predicted_states):
            task_id = self.computation_manager.submit_predictive_computation(
                task_type=f"predictive_frontier_detection_{i}",
                robot_position=predicted_state.position,
                map_data=current_map,
                computation_func=self._compute_frontiers_for_predicted_state,
                priority=10 - i,  # è¶Šè¿‘çš„é¢„æµ‹ä¼˜å…ˆçº§è¶Šé«˜
                predicted_state=predicted_state,
                current_goal=current_goal
            )
            task_ids.append(task_id)
            
        self.last_prediction_time = current_time
        self.prediction_stats['total_predictions'] += len(task_ids)
        
        self.node.get_logger().debug(f'ğŸ”® è§¦å‘é¢„æµ‹æ€§æ£€æµ‹: {len(task_ids)}ä¸ªä»»åŠ¡')
        return task_ids[0] if task_ids else ""
        
    def get_predicted_frontiers(self, 
                              robot_position: Tuple[float, float],
                              max_age: float = 5.0) -> Optional[List[OptimizedFrontierPoint]]:
        """
        è·å–é¢„æµ‹çš„å‰æ²¿ç‚¹
        
        Args:
            robot_position: å½“å‰æœºå™¨äººä½ç½®
            max_age: æœ€å¤§ç»“æœå¹´é¾„(ç§’)
            
        Returns:
            Optional[List[OptimizedFrontierPoint]]: é¢„æµ‹çš„å‰æ²¿ç‚¹åˆ—è¡¨
        """
        # è·å–æœ€ä½³å¯ç”¨é¢„æµ‹ç»“æœ
        best_result = self.computation_manager.get_best_available_result(
            task_type="predictive_frontier_detection",
            robot_position=robot_position,
            max_age=max_age
        )
        
        if best_result and best_result.result_data:
            prediction = best_result.result_data
            if isinstance(prediction, FrontierPrediction):
                self.prediction_stats['cache_hits'] += 1
                self.node.get_logger().debug(
                    f'ğŸ¯ è·å–é¢„æµ‹å‰æ²¿ç‚¹: {len(prediction.frontiers)}ä¸ª, '
                    f'æœ‰æ•ˆæ€§: {prediction.validity_score:.2f}'
                )
                return prediction.frontiers
                
        return None
        
    def get_best_predicted_target(self, 
                                robot_position: Tuple[float, float],
                                evaluation_func: callable) -> Optional[OptimizedFrontierPoint]:
        """
        è·å–æœ€ä½³é¢„æµ‹ç›®æ ‡ç‚¹
        
        Args:
            robot_position: å½“å‰æœºå™¨äººä½ç½®
            evaluation_func: è¯„ä¼°å‡½æ•°
            
        Returns:
            Optional[OptimizedFrontierPoint]: æœ€ä½³é¢„æµ‹ç›®æ ‡ç‚¹
        """
        predicted_frontiers = self.get_predicted_frontiers(robot_position)
        
        if not predicted_frontiers:
            return None
            
        # ä½¿ç”¨è¯„ä¼°å‡½æ•°é€‰æ‹©æœ€ä½³ç›®æ ‡
        original_frontiers = None
        try:
            # ä¸´æ—¶ä¿å­˜åŸå§‹å‰æ²¿ç‚¹åˆ—è¡¨
            original_frontiers = self.node.frontiers
            # è®¾ç½®é¢„æµ‹çš„å‰æ²¿ç‚¹åˆ—è¡¨
            self.node.frontiers = predicted_frontiers

            # è°ƒç”¨è¯„ä¼°å‡½æ•°ï¼ˆåªä¼ é€’æœºå™¨äººä½ç½®ï¼‰
            best_frontier = evaluation_func(robot_position)

            if best_frontier:
                self.prediction_stats['successful_predictions'] += 1
                self.node.get_logger().info(
                    f'ğŸ¯ é¢„æµ‹ç›®æ ‡é€‰æ‹©æˆåŠŸ: ({best_frontier.x:.2f}, {best_frontier.y:.2f})'
                )
            return best_frontier
        except Exception as e:
            self.node.get_logger().error(f'âŒ é¢„æµ‹ç›®æ ‡è¯„ä¼°å¼‚å¸¸: {e}')
            return None
        finally:
            # ç¡®ä¿æ¢å¤åŸå§‹å‰æ²¿ç‚¹åˆ—è¡¨
            if original_frontiers is not None:
                self.node.frontiers = original_frontiers
            
    def _should_trigger_prediction(self, current_map: OccupancyGrid, current_time: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘é¢„æµ‹"""
        # æ£€æŸ¥æ—¶é—´é—´éš”
        if current_time - self.last_prediction_time < self.prediction_interval:
            return False
            
        # æ£€æŸ¥åœ°å›¾å˜åŒ–
        current_map_hash = self._calculate_map_hash(current_map)
        if current_map_hash != self.last_map_hash:
            self.last_map_hash = current_map_hash
            return True
            
        # æ£€æŸ¥æœºå™¨äººçŠ¶æ€å˜åŒ–
        if not self.current_robot_state:
            return True
            
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¿åŠ¨
        if self.robot_velocity:
            speed = math.sqrt(self.robot_velocity.linear.x**2 + self.robot_velocity.linear.y**2)
            if speed > 0.1:  # æœºå™¨äººåœ¨è¿åŠ¨
                return True
                
        return False
        
    def _generate_predicted_robot_states(self, current_goal: Optional[Point]) -> List[PredictedRobotState]:
        """ç”Ÿæˆé¢„æµ‹çš„æœºå™¨äººçŠ¶æ€"""
        if not self.current_robot_state:
            return []
            
        predicted_states = []
        current_time = time.time()
        
        # åŸºäºå½“å‰é€Ÿåº¦é¢„æµ‹æœªæ¥ä½ç½®
        if self.robot_velocity and current_goal:
            for i in range(1, self.motion_prediction_samples + 1):
                dt = (self.prediction_horizon / self.motion_prediction_samples) * i
                
                # ç®€å•çš„çº¿æ€§è¿åŠ¨é¢„æµ‹
                predicted_x = self.current_robot_state.position[0] + self.robot_velocity.linear.x * dt
                predicted_y = self.current_robot_state.position[1] + self.robot_velocity.linear.y * dt
                predicted_yaw = self.current_robot_state.yaw + self.robot_velocity.angular.z * dt
                
                # è€ƒè™‘ç›®æ ‡å¯¼å‘çš„ä¿®æ­£
                if current_goal:
                    goal_direction = math.atan2(
                        current_goal.y - predicted_y,
                        current_goal.x - predicted_x
                    )
                    # æ··åˆå½“å‰æœå‘å’Œç›®æ ‡æ–¹å‘
                    predicted_yaw = 0.7 * predicted_yaw + 0.3 * goal_direction
                
                confidence = max(0.1, 1.0 - dt / self.prediction_horizon)
                
                predicted_states.append(PredictedRobotState(
                    position=(predicted_x, predicted_y),
                    yaw=predicted_yaw,
                    timestamp=current_time + dt,
                    confidence=confidence
                ))
        else:
            # å¦‚æœæ²¡æœ‰é€Ÿåº¦ä¿¡æ¯ï¼Œä½¿ç”¨å½“å‰ä½ç½®çš„å°èŒƒå›´é¢„æµ‹
            for i in range(self.motion_prediction_samples):
                angle = 2 * math.pi * i / self.motion_prediction_samples
                radius = 1.0  # 1ç±³åŠå¾„çš„é¢„æµ‹èŒƒå›´
                
                predicted_x = self.current_robot_state.position[0] + radius * math.cos(angle)
                predicted_y = self.current_robot_state.position[1] + radius * math.sin(angle)
                
                predicted_states.append(PredictedRobotState(
                    position=(predicted_x, predicted_y),
                    yaw=angle,
                    timestamp=current_time + 1.0,
                    confidence=0.5
                ))
                
        return predicted_states
        
    def _compute_frontiers_for_predicted_state(self, 
                                             map_data: OccupancyGrid,
                                             predicted_state: PredictedRobotState,
                                             **kwargs) -> FrontierPrediction:
        """ä¸ºé¢„æµ‹çŠ¶æ€è®¡ç®—å‰æ²¿ç‚¹"""
        start_time = time.time()
        
        try:
            # ä½¿ç”¨åŸºç¡€æ£€æµ‹å™¨æ£€æµ‹å‰æ²¿ç‚¹
            frontiers = self.base_detector.detect_optimized_frontiers(map_data)
            
            # æ ¹æ®é¢„æµ‹ä½ç½®è¿‡æ»¤å’Œæ’åºå‰æ²¿ç‚¹
            filtered_frontiers = self._filter_frontiers_for_predicted_state(
                frontiers, predicted_state
            )
            
            computation_time = time.time() - start_time
            map_hash = self._calculate_map_hash(map_data)
            
            # è®¡ç®—é¢„æµ‹æœ‰æ•ˆæ€§è¯„åˆ†
            validity_score = self._calculate_prediction_validity(
                predicted_state, frontiers, computation_time
            )
            
            prediction = FrontierPrediction(
                frontiers=filtered_frontiers,
                predicted_robot_state=predicted_state,
                computation_time=computation_time,
                map_hash=map_hash,
                validity_score=validity_score
            )
            
            self.node.get_logger().debug(
                f'ğŸ”® é¢„æµ‹çŠ¶æ€å‰æ²¿ç‚¹è®¡ç®—å®Œæˆ: {len(filtered_frontiers)}ä¸ªå‰æ²¿ç‚¹, '
                f'è€—æ—¶: {computation_time:.3f}s, æœ‰æ•ˆæ€§: {validity_score:.2f}'
            )
            
            return prediction
            
        except Exception as e:
            self.node.get_logger().error(f'âŒ é¢„æµ‹å‰æ²¿ç‚¹è®¡ç®—å¼‚å¸¸: {e}')
            return FrontierPrediction(
                frontiers=[],
                predicted_robot_state=predicted_state,
                computation_time=time.time() - start_time,
                map_hash="",
                validity_score=0.0
            )
            
    def _filter_frontiers_for_predicted_state(self, 
                                            frontiers: List[OptimizedFrontierPoint],
                                            predicted_state: PredictedRobotState) -> List[OptimizedFrontierPoint]:
        """æ ¹æ®é¢„æµ‹çŠ¶æ€è¿‡æ»¤å‰æ²¿ç‚¹"""
        if not frontiers:
            return []
            
        # è®¡ç®—æ¯ä¸ªå‰æ²¿ç‚¹ç›¸å¯¹äºé¢„æµ‹ä½ç½®çš„è¯„åˆ†
        scored_frontiers = []
        
        for frontier in frontiers:
            # è®¡ç®—è·ç¦»
            distance = math.sqrt(
                (frontier.x - predicted_state.position[0])**2 +
                (frontier.y - predicted_state.position[1])**2
            )
            
            # è·ç¦»è¯„åˆ†ï¼ˆè·ç¦»é€‚ä¸­çš„å‰æ²¿ç‚¹è¯„åˆ†æ›´é«˜ï¼‰
            optimal_distance = 3.0  # æœ€ä¼˜è·ç¦»
            distance_score = max(0.0, 1.0 - abs(distance - optimal_distance) / optimal_distance)
            
            # æ–¹å‘è¯„åˆ†ï¼ˆä¸é¢„æµ‹æœå‘ä¸€è‡´çš„å‰æ²¿ç‚¹è¯„åˆ†æ›´é«˜ï¼‰
            angle_to_frontier = math.atan2(
                frontier.y - predicted_state.position[1],
                frontier.x - predicted_state.position[0]
            )
            angle_diff = abs(angle_to_frontier - predicted_state.yaw)
            angle_diff = min(angle_diff, 2 * math.pi - angle_diff)  # å–è¾ƒå°è§’åº¦
            direction_score = max(0.0, 1.0 - angle_diff / math.pi)
            
            # ç»¼åˆè¯„åˆ†
            total_score = (distance_score * 0.6 + direction_score * 0.4) * predicted_state.confidence
            
            scored_frontiers.append((frontier, total_score))
            
        # æŒ‰è¯„åˆ†æ’åºå¹¶è¿”å›å‰Nä¸ª
        scored_frontiers.sort(key=lambda x: x[1], reverse=True)
        max_frontiers = min(20, len(scored_frontiers))  # æœ€å¤šè¿”å›20ä¸ªå‰æ²¿ç‚¹
        
        return [frontier for frontier, score in scored_frontiers[:max_frontiers]]
        
    def _calculate_prediction_validity(self, 
                                     predicted_state: PredictedRobotState,
                                     frontiers: List[OptimizedFrontierPoint],
                                     computation_time: float) -> float:
        """è®¡ç®—é¢„æµ‹æœ‰æ•ˆæ€§è¯„åˆ†"""
        # åŸºç¡€æœ‰æ•ˆæ€§åŸºäºé¢„æµ‹ç½®ä¿¡åº¦
        base_validity = predicted_state.confidence
        
        # å‰æ²¿ç‚¹æ•°é‡å› å­
        frontier_factor = min(1.0, len(frontiers) / 10.0)  # 10ä¸ªå‰æ²¿ç‚¹ä¸ºæ»¡åˆ†
        
        # è®¡ç®—æ—¶é—´å› å­
        time_factor = max(0.0, 1.0 - computation_time / 1.0)  # 1ç§’å†…å®Œæˆä¸ºæ»¡åˆ†
        
        # æ—¶é—´æ–°é²œåº¦å› å­
        age = time.time() - predicted_state.timestamp
        freshness_factor = max(0.0, 1.0 - age / 10.0)  # 10ç§’å†…ä¸ºæœ‰æ•ˆ
        
        # ç»¼åˆè¯„åˆ†
        validity = (base_validity * 0.4 + 
                   frontier_factor * 0.3 + 
                   time_factor * 0.2 + 
                   freshness_factor * 0.1)
                   
        return min(1.0, max(0.0, validity))
        
    def _calculate_map_hash(self, map_data: OccupancyGrid) -> str:
        """è®¡ç®—åœ°å›¾å“ˆå¸Œå€¼"""
        try:
            data_array = np.array(map_data.data, dtype=np.int8)
            return str(hash(data_array.tobytes()))
        except Exception:
            return str(time.time())
            
    def get_statistics(self) -> Dict[str, any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_predictions = max(1, self.prediction_stats['total_predictions'])
        
        return {
            **self.prediction_stats,
            'success_rate': self.prediction_stats['successful_predictions'] / total_predictions,
            'cache_hit_rate': self.prediction_stats['cache_hits'] / total_predictions,
            'active_predictions': len(self.active_predictions)
        }
