#!/usr/bin/env python3
"""
ğŸ”„ å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨
å®ç°é¢„æµ‹æ€§ç›®æ ‡è®¡ç®—å’Œå¹¶è¡Œå‰æ²¿ç‚¹å¤„ç†

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åœ¨å½“å‰ç›®æ ‡æ‰§è¡Œè¿‡ç¨‹ä¸­å¹¶è¡Œè®¡ç®—ä¸‹ä¸€ä¸ªç›®æ ‡
2. æ”¯æŒå¼‚æ­¥å‰æ²¿ç‚¹æ£€æµ‹å’Œè¯„ä¼°
3. æ™ºèƒ½ç¼“å­˜ç®¡ç†å’Œç»“æœé¢„æµ‹
4. çŠ¶æ€åŒæ­¥å’Œä¸€è‡´æ€§ä¿è¯

ç®—æ³•ç‰¹ç‚¹ï¼š
- é¢„æµ‹æ€§è®¡ç®—ï¼šåœ¨ç›®æ ‡åˆ‡æ¢å‰æå‰å‡†å¤‡ä¸‹ä¸€ä¸ªç›®æ ‡
- å¹¶è¡Œå¤„ç†ï¼šå¤šçº¿ç¨‹å¤„ç†å‰æ²¿ç‚¹æ£€æµ‹å’Œè¯„ä¼°
- æ™ºèƒ½ç¼“å­˜ï¼šåŸºäºåœ°å›¾å˜åŒ–çš„ç¼“å­˜å¤±æ•ˆç­–ç•¥
- å®¹é”™æœºåˆ¶ï¼šå¤„ç†å¹¶å‘è®¡ç®—ä¸­çš„å¼‚å¸¸æƒ…å†µ

ä½œè€…: Auroraæ¢ç´¢ç³»ç»Ÿ
æ—¥æœŸ: 2025-07-21
"""

import threading
import time
import queue
import copy
from concurrent.futures import ThreadPoolExecutor, Future
from typing import List, Optional, Dict, Tuple, Callable, Any
from dataclasses import dataclass, field
from enum import Enum
import numpy as np
from nav_msgs.msg import OccupancyGrid
from geometry_msgs.msg import Point
import rclpy
from rclpy.node import Node

class ComputationState(Enum):
    """è®¡ç®—çŠ¶æ€æšä¸¾"""
    IDLE = "idle"
    COMPUTING = "computing"
    READY = "ready"
    EXPIRED = "expired"
    ERROR = "error"

@dataclass
class ComputationTask:
    """è®¡ç®—ä»»åŠ¡"""
    task_id: str
    task_type: str  # 'frontier_detection', 'frontier_evaluation', 'target_selection'
    priority: int = 0
    created_time: float = field(default_factory=time.time)
    map_hash: str = ""
    robot_position: Tuple[float, float] = (0.0, 0.0)
    parameters: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ComputationResult:
    """è®¡ç®—ç»“æœ"""
    task_id: str
    state: ComputationState
    result_data: Any = None
    computation_time: float = 0.0
    created_time: float = field(default_factory=time.time)
    expiry_time: float = 0.0
    confidence: float = 1.0
    error_message: str = ""

class ParallelComputationManager:
    """å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨"""
    
    def __init__(self, node: Node, max_workers: int = 4):
        """
        åˆå§‹åŒ–å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨
        
        Args:
            node: ROS2èŠ‚ç‚¹
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        """
        self.node = node
        self.max_workers = max_workers
        
        # çº¿ç¨‹æ± 
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        
        # ä»»åŠ¡é˜Ÿåˆ—
        self.task_queue = queue.PriorityQueue()
        self.active_tasks: Dict[str, Future] = {}
        
        # ç»“æœç¼“å­˜
        self.result_cache: Dict[str, ComputationResult] = {}
        self.cache_lock = threading.RLock()
        
        # çŠ¶æ€ç®¡ç†
        self.is_running = True
        self.computation_stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'average_computation_time': 0.0
        }
        
        # é…ç½®å‚æ•°
        self.cache_expiry_time = 30.0  # ç¼“å­˜è¿‡æœŸæ—¶é—´(ç§’)
        self.max_cache_size = 100      # æœ€å¤§ç¼“å­˜å¤§å°
        self.prediction_horizon = 10.0  # é¢„æµ‹æ—¶é—´èŒƒå›´(ç§’)

        # ğŸš€ å¢å¼ºå¹¶è¡Œå¤„ç†é…ç½®
        self.batch_processing_enabled = True  # å¯ç”¨æ‰¹å¤„ç†
        self.max_batch_size = 20             # æœ€å¤§æ‰¹å¤„ç†å¤§å°
        self.parallel_frontier_detection = True  # å¹¶è¡Œå‰æ²¿ç‚¹æ£€æµ‹
        self.parallel_info_gain_calculation = True  # å¹¶è¡Œä¿¡æ¯å¢ç›Šè®¡ç®—
        self.adaptive_worker_scaling = True  # è‡ªé€‚åº”å·¥ä½œçº¿ç¨‹ç¼©æ”¾
        
        # å¯åŠ¨åå°å¤„ç†çº¿ç¨‹
        self.processing_thread = threading.Thread(target=self._background_processor, daemon=True)
        self.processing_thread.start()
        
        self.node.get_logger().info('ğŸ”„ å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ')

    def submit_batch_frontier_evaluation(self,
                                       frontiers: List,
                                       robot_position: Tuple[float, float],
                                       map_data: OccupancyGrid,
                                       evaluation_func: Callable,
                                       **kwargs) -> str:
        """
        æäº¤æ‰¹é‡å‰æ²¿ç‚¹è¯„ä¼°ä»»åŠ¡

        Args:
            frontiers: å‰æ²¿ç‚¹åˆ—è¡¨
            robot_position: æœºå™¨äººä½ç½®
            map_data: åœ°å›¾æ•°æ®
            evaluation_func: è¯„ä¼°å‡½æ•°
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            str: ä»»åŠ¡ID
        """
        if not self.batch_processing_enabled or len(frontiers) <= 1:
            # å›é€€åˆ°å•ä¸ªå¤„ç†
            return self.submit_predictive_computation(
                'frontier_evaluation', robot_position, map_data,
                evaluation_func, frontiers=frontiers, **kwargs
            )

        # ğŸš€ æ‰¹é‡å¹¶è¡Œå¤„ç†
        task_id = f"batch_evaluation_{int(time.time() * 1000)}"

        # å°†å‰æ²¿ç‚¹åˆ†æ‰¹
        batches = self._create_frontier_batches(frontiers)

        # æäº¤å¹¶è¡Œè¯„ä¼°ä»»åŠ¡
        batch_futures = []
        for i, batch in enumerate(batches):
            batch_task_id = f"{task_id}_batch_{i}"
            future = self.executor.submit(
                self._evaluate_frontier_batch,
                batch, robot_position, map_data, evaluation_func, **kwargs
            )
            batch_futures.append((batch_task_id, future))

        # æäº¤ç»“æœèšåˆä»»åŠ¡
        aggregation_future = self.executor.submit(
            self._aggregate_batch_results, batch_futures, task_id
        )

        self.active_tasks[task_id] = aggregation_future
        self.computation_stats['total_tasks'] += 1

        self.node.get_logger().debug(f'ğŸš€ æäº¤æ‰¹é‡å‰æ²¿ç‚¹è¯„ä¼°: {len(frontiers)}ä¸ªå‰æ²¿ç‚¹, {len(batches)}ä¸ªæ‰¹æ¬¡')
        return task_id

    def submit_parallel_info_gain_calculation(self,
                                             frontiers: List,
                                             robot_position: Tuple[float, float],
                                             map_data: OccupancyGrid,
                                             info_gain_func: Callable,
                                             **kwargs) -> str:
        """
        æäº¤å¹¶è¡Œä¿¡æ¯å¢ç›Šè®¡ç®—ä»»åŠ¡

        Args:
            frontiers: å‰æ²¿ç‚¹åˆ—è¡¨
            robot_position: æœºå™¨äººä½ç½®
            map_data: åœ°å›¾æ•°æ®
            info_gain_func: ä¿¡æ¯å¢ç›Šè®¡ç®—å‡½æ•°
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            str: ä»»åŠ¡ID
        """
        if not self.parallel_info_gain_calculation:
            return self.submit_predictive_computation(
                'info_gain_calculation', robot_position, map_data,
                info_gain_func, frontiers=frontiers, **kwargs
            )

        task_id = f"parallel_info_gain_{int(time.time() * 1000)}"

        # ğŸ”„ å¹¶è¡Œè®¡ç®—æ¯ä¸ªå‰æ²¿ç‚¹çš„ä¿¡æ¯å¢ç›Š
        info_gain_futures = []
        for i, frontier in enumerate(frontiers):
            future = self.executor.submit(
                self._calculate_single_info_gain,
                frontier, robot_position, map_data, info_gain_func, **kwargs
            )
            info_gain_futures.append((i, future))

        # èšåˆç»“æœ
        aggregation_future = self.executor.submit(
            self._aggregate_info_gain_results, info_gain_futures, frontiers, task_id
        )

        self.active_tasks[task_id] = aggregation_future
        self.computation_stats['total_tasks'] += 1

        self.node.get_logger().debug(f'ğŸ”„ æäº¤å¹¶è¡Œä¿¡æ¯å¢ç›Šè®¡ç®—: {len(frontiers)}ä¸ªå‰æ²¿ç‚¹')
        return task_id

    def submit_predictive_computation(self,
                                    task_type: str,
                                    robot_position: Tuple[float, float],
                                    map_data: OccupancyGrid,
                                    computation_func: Callable,
                                    priority: int = 0,
                                    **kwargs) -> str:
        """
        æäº¤é¢„æµ‹æ€§è®¡ç®—ä»»åŠ¡
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            robot_position: æœºå™¨äººä½ç½®
            map_data: åœ°å›¾æ•°æ®
            computation_func: è®¡ç®—å‡½æ•°
            priority: ä»»åŠ¡ä¼˜å…ˆçº§(æ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜)
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            str: ä»»åŠ¡ID
        """
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = f"{task_type}_{int(time.time() * 1000)}"
        
        # è®¡ç®—åœ°å›¾å“ˆå¸Œ
        map_hash = self._calculate_map_hash(map_data)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{task_type}_{map_hash}_{robot_position[0]:.1f}_{robot_position[1]:.1f}"
        cached_result = self._get_cached_result(cache_key)
        
        if cached_result and cached_result.state == ComputationState.READY:
            self.computation_stats['cache_hits'] += 1
            self.node.get_logger().debug(f'ğŸ¯ ç¼“å­˜å‘½ä¸­: {task_type}')
            # å°†ç¼“å­˜ç»“æœæ·»åŠ åˆ°æ´»åŠ¨ä»»åŠ¡ä¸­ï¼Œä»¥ä¾¿get_computation_resultå¯ä»¥æ‰¾åˆ°
            from concurrent.futures import Future
            future = Future()
            future.set_result(cached_result)
            self.active_tasks[task_id] = future
            return task_id
            
        # åˆ›å»ºè®¡ç®—ä»»åŠ¡
        task = ComputationTask(
            task_id=task_id,
            task_type=task_type,
            priority=priority,
            map_hash=map_hash,
            robot_position=robot_position,
            parameters={
                'map_data': copy.deepcopy(map_data),
                'computation_func': computation_func,
                'cache_key': cache_key,
                **kwargs
            }
        )
        
        # æäº¤ä»»åŠ¡
        future = self.executor.submit(self._execute_computation_task, task)
        self.active_tasks[task_id] = future
        
        self.computation_stats['total_tasks'] += 1
        self.computation_stats['cache_misses'] += 1
        
        self.node.get_logger().debug(f'ğŸ”„ æäº¤é¢„æµ‹æ€§è®¡ç®—ä»»åŠ¡: {task_type}, ID: {task_id}')
        return task_id
        
    def get_computation_result(self, task_id: str, timeout: float = 0.1) -> Optional[ComputationResult]:
        """
        è·å–è®¡ç®—ç»“æœ
        
        Args:
            task_id: ä»»åŠ¡ID
            timeout: è¶…æ—¶æ—¶é—´(ç§’)
            
        Returns:
            Optional[ComputationResult]: è®¡ç®—ç»“æœï¼Œå¦‚æœæœªå®Œæˆè¿”å›None
        """
        # æ£€æŸ¥æ´»åŠ¨ä»»åŠ¡
        if task_id in self.active_tasks:
            future = self.active_tasks[task_id]
            try:
                if future.done():
                    result = future.result()
                    del self.active_tasks[task_id]
                    return result
                elif timeout > 0:
                    result = future.result(timeout=timeout)
                    del self.active_tasks[task_id]
                    return result
            except Exception as e:
                import traceback
                error_details = traceback.format_exc()
                self.node.get_logger().error(f'âŒ è·å–è®¡ç®—ç»“æœå¼‚å¸¸: {task_id} - {e}')
                self.node.get_logger().error(f'âŒ è¯¦ç»†é”™è¯¯ä¿¡æ¯: {error_details}')
                if task_id in self.active_tasks:
                    del self.active_tasks[task_id]
                # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯Noneï¼Œé¿å…è°ƒç”¨è€…å‡ºé”™
                return ComputationResult(
                    task_id=task_id,
                    state=ComputationState.ERROR,
                    result_data=None,
                    error_message=str(e)
                )
                    
        # æ£€æŸ¥ç¼“å­˜
        with self.cache_lock:
            for result in self.result_cache.values():
                if result.task_id == task_id:
                    return result
                    
        return None
        
    def get_best_available_result(self, task_type: str, 
                                robot_position: Tuple[float, float],
                                max_age: float = 10.0) -> Optional[ComputationResult]:
        """
        è·å–æœ€ä½³å¯ç”¨ç»“æœ
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            robot_position: æœºå™¨äººä½ç½®
            max_age: æœ€å¤§ç»“æœå¹´é¾„(ç§’)
            
        Returns:
            Optional[ComputationResult]: æœ€ä½³å¯ç”¨ç»“æœ
        """
        current_time = time.time()
        best_result = None
        best_score = -float('inf')
        
        with self.cache_lock:
            for result in self.result_cache.values():
                if (result.task_id.startswith(task_type) and 
                    result.state == ComputationState.READY and
                    current_time - result.created_time <= max_age):
                    
                    # è®¡ç®—ç»“æœè¯„åˆ†ï¼ˆåŸºäºæ—¶é—´æ–°é²œåº¦å’Œä½ç½®ç›¸å…³æ€§ï¼‰
                    age_factor = 1.0 - (current_time - result.created_time) / max_age
                    
                    # è®¡ç®—ä½ç½®ç›¸å…³æ€§
                    if hasattr(result, 'robot_position'):
                        distance = np.sqrt(
                            (robot_position[0] - result.robot_position[0])**2 +
                            (robot_position[1] - result.robot_position[1])**2
                        )
                        position_factor = max(0.0, 1.0 - distance / 5.0)  # 5ç±³å†…ç›¸å…³æ€§è¾ƒé«˜
                    else:
                        position_factor = 0.5
                        
                    score = (age_factor * 0.6 + position_factor * 0.4) * result.confidence
                    
                    if score > best_score:
                        best_score = score
                        best_result = result
                        
        return best_result
        
    def _execute_computation_task(self, task: ComputationTask) -> ComputationResult:
        """æ‰§è¡Œè®¡ç®—ä»»åŠ¡"""
        start_time = time.time()
        result = ComputationResult(
            task_id=task.task_id,
            state=ComputationState.COMPUTING
        )
        
        try:
            # æ‰§è¡Œè®¡ç®—
            computation_func = task.parameters['computation_func']
            computation_args = {k: v for k, v in task.parameters.items() 
                              if k not in ['computation_func', 'cache_key']}
            
            result_data = computation_func(**computation_args)
            
            # æ›´æ–°ç»“æœ
            computation_time = time.time() - start_time
            result.state = ComputationState.READY
            result.result_data = result_data
            result.computation_time = computation_time
            result.expiry_time = time.time() + self.cache_expiry_time
            
            # ç¼“å­˜ç»“æœ
            cache_key = task.parameters.get('cache_key', task.task_id)
            self._cache_result(cache_key, result)
            
            # æ›´æ–°ç»Ÿè®¡
            self.computation_stats['completed_tasks'] += 1
            self._update_average_computation_time(computation_time)
            
            self.node.get_logger().debug(
                f'âœ… è®¡ç®—ä»»åŠ¡å®Œæˆ: {task.task_type}, è€—æ—¶: {computation_time:.3f}s'
            )
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            result.state = ComputationState.ERROR
            result.error_message = f"{str(e)} | {error_details}"
            self.node.get_logger().error(f'âŒ è®¡ç®—ä»»åŠ¡å¼‚å¸¸: {task.task_type}, é”™è¯¯: {e}')
            self.node.get_logger().error(f'âŒ è¯¦ç»†é”™è¯¯ä¿¡æ¯: {error_details}')
            
        return result
        
    def _background_processor(self):
        """åå°å¤„ç†çº¿ç¨‹"""
        while self.is_running:
            try:
                # æ¸…ç†è¿‡æœŸç¼“å­˜
                self._cleanup_expired_cache()
                
                # æ¸…ç†å®Œæˆçš„ä»»åŠ¡
                self._cleanup_completed_tasks()
                
                time.sleep(1.0)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                self.node.get_logger().error(f'âŒ åå°å¤„ç†å¼‚å¸¸: {e}')
                
    def _calculate_map_hash(self, map_data: OccupancyGrid) -> str:
        """è®¡ç®—åœ°å›¾å“ˆå¸Œå€¼"""
        try:
            # ä½¿ç”¨åœ°å›¾æ•°æ®çš„ç®€åŒ–å“ˆå¸Œ
            data_array = np.array(map_data.data, dtype=np.int8)
            return str(hash(data_array.tobytes()))
        except Exception:
            return str(time.time())
            
    def _get_cached_result(self, cache_key: str) -> Optional[ComputationResult]:
        """è·å–ç¼“å­˜ç»“æœ"""
        with self.cache_lock:
            result = self.result_cache.get(cache_key)
            if result and time.time() < result.expiry_time:
                return result
            elif result:
                # è¿‡æœŸç»“æœï¼Œåˆ é™¤
                del self.result_cache[cache_key]
        return None
        
    def _cache_result(self, cache_key: str, result: ComputationResult):
        """ç¼“å­˜ç»“æœ"""
        with self.cache_lock:
            # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
            if len(self.result_cache) >= self.max_cache_size:
                # åˆ é™¤æœ€æ—§çš„ç»“æœ
                oldest_key = min(self.result_cache.keys(), 
                               key=lambda k: self.result_cache[k].created_time)
                del self.result_cache[oldest_key]
                
            self.result_cache[cache_key] = result
            
    def _cleanup_expired_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        current_time = time.time()
        with self.cache_lock:
            expired_keys = [
                key for key, result in self.result_cache.items()
                if current_time >= result.expiry_time
            ]
            for key in expired_keys:
                del self.result_cache[key]
                
    def _cleanup_completed_tasks(self):
        """æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡"""
        completed_tasks = [
            task_id for task_id, future in self.active_tasks.items()
            if future.done()
        ]
        for task_id in completed_tasks:
            del self.active_tasks[task_id]
            
    def _update_average_computation_time(self, computation_time: float):
        """æ›´æ–°å¹³å‡è®¡ç®—æ—¶é—´"""
        completed = self.computation_stats['completed_tasks']
        if completed > 1:
            current_avg = self.computation_stats['average_computation_time']
            new_avg = (current_avg * (completed - 1) + computation_time) / completed
            self.computation_stats['average_computation_time'] = new_avg
        else:
            self.computation_stats['average_computation_time'] = computation_time
            
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.cache_lock:
            cache_size = len(self.result_cache)
            
        return {
            **self.computation_stats,
            'active_tasks': len(self.active_tasks),
            'cache_size': cache_size,
            'cache_hit_rate': (
                self.computation_stats['cache_hits'] / 
                max(1, self.computation_stats['cache_hits'] + self.computation_stats['cache_misses'])
            )
        }
        
    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        try:
            self.is_running = False

            # ç­‰å¾…çŸ­æ—¶é—´è®©æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡å®Œæˆ
            import time
            time.sleep(0.1)

            # å–æ¶ˆæ‰€æœ‰æ´»åŠ¨ä»»åŠ¡
            for task_id, future in list(self.active_tasks.items()):
                try:
                    if not future.done():
                        future.cancel()
                except Exception:
                    pass  # å¿½ç•¥å–æ¶ˆä»»åŠ¡æ—¶çš„å¼‚å¸¸

            # æ¸…ç©ºä»»åŠ¡é˜Ÿåˆ—
            while not self.task_queue.empty():
                try:
                    self.task_queue.get_nowait()
                except:
                    break

            # æ¸…ç©ºæ´»åŠ¨ä»»åŠ¡
            self.active_tasks.clear()

            # å…³é—­çº¿ç¨‹æ± ï¼ˆä¸ç­‰å¾…ï¼Œé¿å…é˜»å¡ï¼‰
            try:
                self.executor.shutdown(wait=False)
                print("âœ… çº¿ç¨‹æ± å·²å…³é—­")
            except Exception as e:
                print(f"âš ï¸ çº¿ç¨‹æ± å…³é—­å¼‚å¸¸: {e}")

            print('âœ… å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨å…³é—­å®Œæˆ')

        except Exception as e:
            print(f'âŒ å¹¶è¡Œè®¡ç®—ç®¡ç†å™¨å…³é—­å¼‚å¸¸: {e}')
            import traceback
            print(f'âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}')

    def _create_frontier_batches(self, frontiers: List) -> List[List]:
        """åˆ›å»ºå‰æ²¿ç‚¹æ‰¹æ¬¡"""
        if len(frontiers) <= self.max_batch_size:
            return [frontiers]

        batches = []
        for i in range(0, len(frontiers), self.max_batch_size):
            batch = frontiers[i:i + self.max_batch_size]
            batches.append(batch)

        return batches

    def _evaluate_frontier_batch(self, batch: List, robot_position: Tuple[float, float],
                               map_data: OccupancyGrid, evaluation_func: Callable, **kwargs) -> List:
        """è¯„ä¼°å‰æ²¿ç‚¹æ‰¹æ¬¡"""
        try:
            batch_results = []
            for frontier in batch:
                try:
                    result = evaluation_func(frontier, robot_position, map_data, **kwargs)
                    batch_results.append((frontier, result))
                except Exception as e:
                    self.node.get_logger().error(f'âŒ å‰æ²¿ç‚¹è¯„ä¼°å¼‚å¸¸: {e}')
                    batch_results.append((frontier, 0.0))  # é»˜è®¤è¯„åˆ†

            return batch_results
        except Exception as e:
            self.node.get_logger().error(f'âŒ æ‰¹æ¬¡è¯„ä¼°å¼‚å¸¸: {e}')
            return [(frontier, 0.0) for frontier in batch]

    def _aggregate_batch_results(self, batch_futures: List, task_id: str) -> ComputationResult:
        """èšåˆæ‰¹æ¬¡ç»“æœ"""
        try:
            all_results = []
            total_computation_time = 0.0

            for batch_task_id, future in batch_futures:
                try:
                    start_time = time.time()
                    batch_result = future.result(timeout=45.0)  # 45ç§’è¶…æ—¶
                    computation_time = time.time() - start_time
                    total_computation_time += computation_time

                    all_results.extend(batch_result)
                except Exception as e:
                    self.node.get_logger().error(f'âŒ æ‰¹æ¬¡ç»“æœè·å–å¼‚å¸¸: {e}')

            # åˆ›å»ºèšåˆç»“æœ
            result = ComputationResult(
                task_id=task_id,
                state=ComputationState.READY,
                result_data=all_results,
                computation_time=total_computation_time,
                confidence=0.9 if all_results else 0.0
            )

            return result

        except Exception as e:
            self.node.get_logger().error(f'âŒ ç»“æœèšåˆå¼‚å¸¸: {e}')
            return ComputationResult(
                task_id=task_id,
                state=ComputationState.ERROR,
                error_message=str(e)
            )

    def _calculate_single_info_gain(self, frontier, robot_position: Tuple[float, float],
                                  map_data: OccupancyGrid, info_gain_func: Callable, **kwargs) -> float:
        """è®¡ç®—å•ä¸ªå‰æ²¿ç‚¹çš„ä¿¡æ¯å¢ç›Š"""
        try:
            return info_gain_func(frontier, robot_position, map_data, **kwargs)
        except Exception as e:
            self.node.get_logger().error(f'âŒ ä¿¡æ¯å¢ç›Šè®¡ç®—å¼‚å¸¸: {e}')
            return 0.0

    def _aggregate_info_gain_results(self, info_gain_futures: List, frontiers: List, task_id: str) -> ComputationResult:
        """èšåˆä¿¡æ¯å¢ç›Šç»“æœ"""
        try:
            info_gains = [0.0] * len(frontiers)
            total_computation_time = 0.0

            for i, future in info_gain_futures:
                try:
                    start_time = time.time()
                    info_gain = future.result(timeout=20.0)  # 20ç§’è¶…æ—¶
                    computation_time = time.time() - start_time
                    total_computation_time += computation_time

                    info_gains[i] = info_gain
                except Exception as e:
                    self.node.get_logger().error(f'âŒ ä¿¡æ¯å¢ç›Šç»“æœè·å–å¼‚å¸¸: {e}')
                    info_gains[i] = 0.0

            # åˆ›å»ºç»“æœå­—å…¸
            result_data = {
                'frontiers': frontiers,
                'info_gains': info_gains,
                'frontier_info_pairs': list(zip(frontiers, info_gains))
            }

            result = ComputationResult(
                task_id=task_id,
                state=ComputationState.READY,
                result_data=result_data,
                computation_time=total_computation_time,
                confidence=0.95
            )

            return result

        except Exception as e:
            self.node.get_logger().error(f'âŒ ä¿¡æ¯å¢ç›Šèšåˆå¼‚å¸¸: {e}')
            return ComputationResult(
                task_id=task_id,
                state=ComputationState.ERROR,
                error_message=str(e)
            )
